# REMA 1000 Product Scraper

This Python script scrapes all products from REMA 1000's API and saves them as JSONL for import into your Supabase database.

## ğŸš€ Quick Start

### 1. Install Python dependencies:
```bash
cd scripts
pip install -r requirements.txt
```

### 2. Run the scraper:
```bash
python rema_scraper.py
```

### 3. Output:
- **File:** `data/rema_products.jsonl`
- **Format:** One JSON object per line
- **Data:** Complete product information including prices, nutrition, images, etc.

## ğŸ“Š What it scrapes:

- âœ… Product names and descriptions
- âœ… Images (small, medium, large)
- âœ… Prices and unit prices
- âœ… Campaigns and offers
- âœ… Weight/volume and units
- âœ… Categories and departments
- âœ… Ingredient lists and allergens
- âœ… Nutrition information
- âœ… Labels and certifications

## âš¡ Performance:

- **Rate limiting:** 4 requests/second for listing, 10 requests/second for details
- **Retry logic:** Automatic backoff on rate limits (429/503)
- **Progress tracking:** Shows current page and total products found
- **Expected output:** 27,000+ products in ~2-3 hours

## ğŸ”„ Next Steps:

1. **Run scraper** to get all products
2. **Import JSONL** to Supabase via your existing API
3. **Implement delta updates** in your Next.js app
4. **Schedule regular updates** with Vercel Cron

## ğŸ“ File Structure:

```
scripts/
â”œâ”€â”€ rema_scraper.py      # Main scraper script
â”œâ”€â”€ requirements.txt      # Python dependencies
â”œâ”€â”€ README.md           # This file
â””â”€â”€ data/               # Output directory (created automatically)
    â””â”€â”€ rema_products.jsonl  # Scraped products
```
